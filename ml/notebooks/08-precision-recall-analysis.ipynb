{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4544f14d",
   "metadata": {},
   "source": [
    "# MammoScan AI: 08 - Model Championship Playoff\n",
    "\n",
    "## üéØ Goal\n",
    "This notebook is the final competition between our two best models: the retrained **Baseline CNN (v2)** and the **Regularized Transfer Learning Model (v2)**.\n",
    "\n",
    "We will load each model, perform a full Precision-Recall analysis on the unseen test set, find their optimal classification thresholds, and compare their best possible performances side-by-side to declare a single, definitive champion model for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbbf199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "# Import all necessary libraries for our analysis.\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# --- Path Setup ---\n",
    "# This ensures our notebook can find the custom modules in `ml/src`.\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# --- Custom Modules ---\n",
    "# Import our model-building functions. We need these to help load the models robustly.\n",
    "from ml.src.model import build_full_model, create_regularized_transfer_model\n",
    "\n",
    "# --- Constants ---\n",
    "PROCESSED_DATA_DIR = os.path.join(project_root, 'data', 'processed')\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52fc3d",
   "metadata": {},
   "source": [
    "## üì• Step 1: Define Contenders and Load Test Data\n",
    "\n",
    "First, we define the paths to our two \"champion\" model files that were trained with the corrected labels. We then load our `test` dataset and prepare two versions of it: one for our baseline model and one with the special preprocessing required by the EfficientNet transfer learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f304256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset...\n",
      "Found 112 files belonging to 2 classes.\n",
      "‚úÖ Test data is ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 16:11:10.686908: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Ensure our processed data is available locally.\n",
    "# !dvc pull data/processed.dvc\n",
    "\n",
    "# --- Define Our Two Final Contenders ---\n",
    "MODEL_PATHS = {\n",
    "    \"Baseline CNN (v2)\": os.path.join(project_root, 'models', 'checkpoints', 'baseline_model_v2.keras'),\n",
    "    \"Transfer Learning (Regularized v2)\": os.path.join(project_root, 'models', 'checkpoints', 'regularized_fine_tuned_model_v2.keras')\n",
    "}\n",
    "\n",
    "# --- Load the Test Dataset ---\n",
    "print(\"Loading test dataset...\")\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(PROCESSED_DATA_DIR, 'test'),\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary',\n",
    "    shuffle=False # Never shuffle the test set during evaluation\n",
    ")\n",
    "\n",
    "# --- IMPORTANT: Remap labels to match our training (Cancer=1) ---\n",
    "test_dataset = test_dataset.map(lambda x, y: (x, 1 - y))\n",
    "\n",
    "# Create a second version of the dataset for the EfficientNet model\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "test_dataset_preprocessed = test_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Get the true labels, which are the same for both dataset versions\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "class_names = ['Non-Cancer', 'Cancer'] # Class 0, Class 1\n",
    "print(\"‚úÖ Test data is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4c106",
   "metadata": {},
   "source": [
    "## üèÜ Step 2: The Championship Analysis Loop\n",
    "\n",
    "Now for the main event. We'll loop through each contender. For each one, we'll use the specific loading strategy that we know works, get its predictions, and perform the Precision-Recall analysis to find its optimal score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd4854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating: Baseline CNN (v2) ---\n",
      "Re-creating model architecture from source code...\n",
      "Loading weights from /home/mr-rey/Joseph/Projects/Python/mammoscan-AI/models/checkpoints/baseline_model_v2.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mr-rey/miniconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:18: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step\n",
      "‚úÖ Analysis complete.\n",
      "\n",
      "--- Evaluating: Transfer Learning (Regularized v2) ---\n",
      "Re-creating model architecture from source code...\n",
      "Loading weights from /home/mr-rey/Joseph/Projects/Python/mammoscan-AI/models/checkpoints/regularized_fine_tuned_model_v2.keras...\n",
      "‚úÖ Model loaded successfully.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step\n",
      "‚úÖ Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: The Championship Analysis Loop (Corrected)\n",
    "\n",
    "# This list will hold the final results for each model\n",
    "all_results = []\n",
    "\n",
    "for model_name, model_path in MODEL_PATHS.items():\n",
    "    print(f\"\\n--- Evaluating: {model_name} ---\")\n",
    "    \n",
    "    # --- Step 2.1: Select the correct dataset ---\n",
    "    if \"baseline\" in model_name:\n",
    "        eval_dataset = test_dataset\n",
    "    else:\n",
    "        eval_dataset = test_dataset_preprocessed\n",
    "\n",
    "    # --- Step 2.2: Load the Model using the ROBUST STRATEGY ---\n",
    "    print(\"Re-creating model architecture from source code...\")\n",
    "    if \"Baseline\" in model_name:\n",
    "        # For the baseline, we re-create the full model with its augmentation layers\n",
    "        model = build_full_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    else: # For the transfer learning model\n",
    "        # For the transfer model, we re-create its specific architecture\n",
    "        model = create_regularized_transfer_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    \n",
    "    print(f\"Loading weights from {model_path}...\")\n",
    "    # Now, we load ONLY the weights into our clean, local architecture\n",
    "    model.load_weights(model_path)\n",
    "    print(\"‚úÖ Model loaded successfully.\")\n",
    "\n",
    "    # --- Step 2.3: Get Predictions ---\n",
    "    raw_predictions = model.predict(eval_dataset)\n",
    "    \n",
    "    # --- Step 2.4: P-R Curve Analysis ---\n",
    "    precision, recall, thresholds = precision_recall_curve(true_labels, raw_predictions)\n",
    "    \n",
    "    pr_df = pd.DataFrame({\n",
    "        'recall': recall[:-1],\n",
    "        'precision': precision[:-1],\n",
    "        'threshold': thresholds\n",
    "    })\n",
    "\n",
    "    # --- Step 2.5: Find Optimal Threshold for >= 90% Recall ---\n",
    "    high_recall_options = pr_df[pr_df['recall'] >= 0.90]\n",
    "    \n",
    "    if not high_recall_options.empty:\n",
    "        best_option = high_recall_options.loc[high_recall_options['precision'].idxmax()]\n",
    "        \n",
    "        # --- Step 2.6: Store the Results ---\n",
    "        all_results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Best Threshold\": best_option['threshold'],\n",
    "            \"Recall\": best_option['recall'],\n",
    "            \"Precision\": best_option['precision'],\n",
    "        })\n",
    "        print(\"‚úÖ Analysis complete.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No threshold found for {model_name} that achieves at least 90% recall.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bbb03",
   "metadata": {},
   "source": [
    "## üèÅ Step 3: Final Results and Champion Declaration\n",
    "\n",
    "Finally, we'll display our results in a clean table to make a direct, data-driven comparison and declare our champion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b52d8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Championship Results ---\n",
      "Goal: Highest possible Precision while maintaining at least 90% Recall.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Threshold</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline CNN (v2)</td>\n",
       "      <td>0.110593</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transfer Learning (Regularized v2)</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Best Threshold    Recall  Precision\n",
       "0                   Baseline CNN (v2)        0.110593  0.947368   0.580645\n",
       "1  Transfer Learning (Regularized v2)        0.345100  0.947368   0.529412"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ CHAMPION MODEL: Baseline CNN (v2)\n",
      "It achieves a recall of 94.74% and precision of 58.06% at a threshold of 0.1106\n"
     ]
    }
   ],
   "source": [
    "# Convert the results list into a pandas DataFrame for a clean summary table.\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n--- Model Championship Results ---\")\n",
    "print(\"Goal: Highest possible Precision while maintaining at least 90% Recall.\")\n",
    "display(results_df)\n",
    "\n",
    "# Programmatically find and declare the champion.\n",
    "if not results_df.empty:\n",
    "    champion = results_df.loc[results_df['Precision'].idxmax()]\n",
    "    print(f\"\\nüèÜ CHAMPION MODEL: {champion['Model']}\")\n",
    "    print(f\"It achieves a recall of {champion['Recall']:.2%} and precision of {champion['Precision']:.2%} at a threshold of {champion['Best Threshold']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (Python 3.11)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
